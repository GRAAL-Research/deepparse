{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import compress_pickle\n",
    "import pickle\n",
    "from deepparse import download_from_public_repository\n",
    "from deepparse.dataset_container import PickleDatasetContainer\n",
    "from deepparse.parser import AddressParser\n",
    "import shutil\n",
    "from poutyne import set_seeds\n",
    "import poutyne\n",
    "import timeit\n",
    "\n",
    "seed = 42\n",
    "set_seeds(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Retrain an Address Parser for Single Country Uses"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example, we will retrain a pre-trained model to maximize its performance for specific countries (e.g. the UK or Canada)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrain a Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, to retrain our supervised model, we need parsed address example, as shown in the following figure. Fortunately, we have access to a public dataset of such parsed examples, the [Structured Multinational Address Dataset](https://github.com/GRAAL-Research/deepparse-address-data)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![parsing](../docs/source/_static/img/address_parsing.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For our example, we will focus on UK addresses since we want to parse addresses only from the UK. So let's first download the dataset directly from the public repository using Deepparse `download_from_public_repository` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(\"dataset\")\n",
    "download_from_public_repository(\"dataset/data\", \"\", file_extension=\"zip\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset archive is a zip directory of subdirectories in which each country's data is compressed into an LZMA file (a more aggressive compression algorithm). The dataset public repository offers a [script](https://github.com/GRAAL-Research/deepparse-address-data/blob/main/lzma_decompress.py) to decompress the LZMA compress dataset zip archive. We will use the basic idea of it to decompress the dataset in the next code cell (the script handles CLI parameters)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, let's decompress the archive\n",
    "archive_root_path = os.path.join(\"dataset\")\n",
    "archive_path = os.path.join(archive_root_path, \"data.zip\")\n",
    "\n",
    "# Unzip the archive\n",
    "shutil.unpack_archive(archive_path, archive_root_path)\n",
    "\n",
    "# Delete the archive\n",
    "os.remove(archive_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The script functions with minor modification to handle argument\n",
    "# instead or CLI parsed argument\n",
    "\n",
    "\n",
    "# Function to handle the files paths\n",
    "def absolute_file_paths(directory):\n",
    "    \"\"\"\n",
    "    Function to get all the absolute paths of files into a directory.\n",
    "    \"\"\"\n",
    "    for dir_path, _, filenames in os.walk(directory):\n",
    "        for f in filenames:\n",
    "            if f.endswith(\".lzma\"):\n",
    "                yield os.path.abspath(os.path.join(dir_path, f))\n",
    "\n",
    "\n",
    "# Function to LZMA decompress the files_directory into the path_to_save directory\n",
    "def lzma_decompress(files_directory, root_path_to_save) -> None:\n",
    "    \"\"\"\n",
    "    Script to decompress the dataset from LZMA compress files into pickled one.\n",
    "    \"\"\"\n",
    "    paths = absolute_file_paths(files_directory)\n",
    "\n",
    "    for path in paths:\n",
    "        pickled_data = compress_pickle.load(path, compression=\"lzma\")\n",
    "        filename = path.split(os.path.sep)[-1].replace(\".lzma\", \".p\")\n",
    "        file_path = os.path.join(*path.split(os.path.sep)[-4:-1])\n",
    "        path_to_save = os.path.join(root_path_to_save, file_path)\n",
    "        os.makedirs(path_to_save, exist_ok=True)\n",
    "        with open(os.path.join(path_to_save, filename), \"wb\") as file:\n",
    "            pickle.dump(pickled_data, file)\n",
    "        os.remove(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's decompress the dataset. It takes several minutes to decompress.\n",
    "\n",
    "root_dir = os.path.join(\"dataset\", \"data\")\n",
    "clean_root_dir = os.path.join(root_dir, \"clean_data\")\n",
    "clean_train_directory = os.path.join(clean_root_dir, \"train\")\n",
    "clean_test_directory = os.path.join(clean_root_dir, \"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We decompress all the dataset\n",
    "lzma_decompress(root_dir, \"dataset\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's import our train and test datasets into memory to retrain our parser model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_root_dir = os.path.join(root_dir, \"clean_data\")\n",
    "clean_train_directory = os.path.join(clean_root_dir, \"train\")\n",
    "clean_test_directory = os.path.join(clean_root_dir, \"test\")\n",
    "\n",
    "uk_training_data_path = os.path.join(clean_train_directory, \"gb.p\")\n",
    "uk_test_data_path = os.path.join(clean_test_directory, \"gb.p\")\n",
    "\n",
    "training_container = PickleDatasetContainer(uk_training_data_path)\n",
    "test_container = PickleDatasetContainer(uk_test_data_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use the FastText one for our base pre-trained model since it is faster to retrain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading the embeddings model\n"
     ]
    }
   ],
   "source": [
    "address_parser = AddressParser(model_type=\"fasttext\", device=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But first, let's see what the performance is before retraining."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "address_parser.test(test_container, batch_size=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[35mEpoch: \u001B[36m1/5 \u001B[35mTrain steps: \u001B[36m2500 \u001B[35mVal steps: \u001B[36m625 \u001B[32m57.82s \u001B[35mloss:\u001B[94m 0.096870\u001B[35m accuracy:\u001B[94m 99.663765\u001B[35m val_loss:\u001B[94m 0.105059\u001B[35m val_accuracy:\u001B[94m 99.660023\u001B[0m\n",
      "Epoch 1: val_loss improved from inf to 0.10506, saving file to ./uk_faster_retrain/checkpoint_epoch_1.ckpt\n",
      "\u001B[35mEpoch: \u001B[36m2/5 \u001B[35mTrain steps: \u001B[36m2500 \u001B[35mVal steps: \u001B[36m625 \u001B[32m58.84s \u001B[35mloss:\u001B[94m 0.092458\u001B[35m accuracy:\u001B[94m 99.677379\u001B[35m val_loss:\u001B[94m 0.103238\u001B[35m val_accuracy:\u001B[94m 99.672032\u001B[0m\n",
      "Epoch 2: val_loss improved from 0.10506 to 0.10324, saving file to ./uk_faster_retrain/checkpoint_epoch_2.ckpt\n",
      "\u001B[35mEpoch: \u001B[36m3/5 \u001B[35mTrain steps: \u001B[36m2500 \u001B[35mVal steps: \u001B[36m625 \u001B[32m58.43s \u001B[35mloss:\u001B[94m 0.090964\u001B[35m accuracy:\u001B[94m 99.683519\u001B[35m val_loss:\u001B[94m 0.103035\u001B[35m val_accuracy:\u001B[94m 99.673781\u001B[0m\n",
      "Epoch 3: val_loss improved from 0.10324 to 0.10304, saving file to ./uk_faster_retrain/checkpoint_epoch_3.ckpt\n",
      "\u001B[35mEpoch: \u001B[36m4/5 \u001B[35mTrain steps: \u001B[36m2500 \u001B[35mVal steps: \u001B[36m625 \u001B[32m58.37s \u001B[35mloss:\u001B[94m 0.089921\u001B[35m accuracy:\u001B[94m 99.685827\u001B[35m val_loss:\u001B[94m 0.103027\u001B[35m val_accuracy:\u001B[94m 99.673781\u001B[0m\n",
      "Epoch 4: val_loss improved from 0.10304 to 0.10303, saving file to ./uk_faster_retrain/checkpoint_epoch_4.ckpt\n",
      "\u001B[35mEpoch: \u001B[36m5/5 \u001B[35mTrain steps: \u001B[36m2500 \u001B[35mVal steps: \u001B[36m625 \u001B[32m58.31s \u001B[35mloss:\u001B[94m 0.090967\u001B[35m accuracy:\u001B[94m 99.684051\u001B[35m val_loss:\u001B[94m 0.103027\u001B[35m val_accuracy:\u001B[94m 99.673781\u001B[0m\n",
      "Epoch 5: val_loss improved from 0.10303 to 0.10303, saving file to ./uk_faster_retrain/checkpoint_epoch_5.ckpt\n",
      "Restoring data from ./uk_faster_retrain/checkpoint_epoch_5.ckpt\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'epoch': 1,\n",
       "  'time': 57.81894668377936,\n",
       "  'loss': 0.09687001281384341,\n",
       "  'accuracy': 99.66376511882362,\n",
       "  'val_loss': 0.1050588409877063,\n",
       "  'val_accuracy': 99.66002270373627},\n",
       " {'epoch': 2,\n",
       "  'time': 58.83542291820049,\n",
       "  'loss': 0.09245755615734887,\n",
       "  'accuracy': 99.67737932159272,\n",
       "  'val_loss': 0.10323802052373769,\n",
       "  'val_accuracy': 99.67203222624765},\n",
       " {'epoch': 3,\n",
       "  'time': 58.427432637661695,\n",
       "  'loss': 0.090964393501016,\n",
       "  'accuracy': 99.68351861406266,\n",
       "  'val_loss': 0.1030354176204891,\n",
       "  'val_accuracy': 99.67378086061039},\n",
       " {'epoch': 4,\n",
       "  'time': 58.374891674146056,\n",
       "  'loss': 0.08992147407911884,\n",
       "  'accuracy': 99.68582667894091,\n",
       "  'val_loss': 0.10302727049831104,\n",
       "  'val_accuracy': 99.67378086061039},\n",
       " {'epoch': 5,\n",
       "  'time': 58.309186859056354,\n",
       "  'loss': 0.09096737359163201,\n",
       "  'accuracy': 99.68405119942516,\n",
       "  'val_loss': 0.10302683650516546,\n",
       "  'val_accuracy': 99.67378086061039}]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_ = address_parser.retrain(\n",
    "    training_container,\n",
    "    train_ratio=0.8,\n",
    "    epochs=1,\n",
    "    batch_size=32,\n",
    "    num_workers=2,\n",
    "    learning_rate=0.001,\n",
    "    logging_path=\"./uk_retrain\",\n",
    "    name_of_the_retrain_parser=\"UKParser\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running test\n",
      "\u001B[35mTest steps: \u001B[36m57 \u001B[32m1.74s \u001B[35mtest_loss:\u001B[94m 0.120875\u001B[35m test_accuracy:\u001B[94m 99.575062\u001B[0m                                                \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'time': 1.7367468271404505,\n",
       " 'test_loss': 0.12087451704787924,\n",
       " 'test_accuracy': 99.5750624169449}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "address_parser.test(test_container, batch_size=256)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To further improve performance, we could train for longer, increase the training dataset size (the actual size of 100,000 addresses), or rework the Seq2Seq hidden sizes. See the [retrain interface documentation](https://deepparse.org/parser.html#deepparse.parser.AddressParser.retrain) for all the training parameters."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
