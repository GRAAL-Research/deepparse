<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>deepparse.parser.address_parser &mdash; deepparse 0.7.5 documentation</title>
      <link rel="stylesheet" href="../../../_static/pygments.css" type="text/css" />
      <link rel="stylesheet" href="../../../_static/css/theme.css" type="text/css" />
  <!--[if lt IE 9]>
    <script src="../../../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script data-url_root="../../../" id="documentation_options" src="../../../_static/documentation_options.js"></script>
        <script src="../../../_static/jquery.js"></script>
        <script src="../../../_static/underscore.js"></script>
        <script src="../../../_static/_sphinx_javascript_frameworks_compat.js"></script>
        <script src="../../../_static/doctools.js"></script>
    <script src="../../../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../../../genindex.html" />
    <link rel="search" title="Search" href="../../../search.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
            <a href="../../../index.html">
            <img src="../../../_static/deepparse.png" class="logo" alt="Logo"/>
          </a>
              <div class="version">
                0.7.5
              </div>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">API</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../parser.html">Parser</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../dataset_container.html">Dataset Container</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../comparer.html">Comparer</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../cli.html">CLI</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Examples</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../examples/parse_addresses.html">Parse Addresses</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../examples/parse_addresses_with_cli.html">Parse Addresses Using Our CLI</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../examples/retrained_model_parsing.html">Use a Retrained Model to Parse Addresses</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../examples/fine_tuning.html">Retrain a Pretrained Model</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../examples/fine_tuning_with_csv_dataset.html">Retrain a Pretrained Model Using a CSV Dataset</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../examples/retrain_attention_model.html">Retrain an attention mechanism model</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../examples/retrain_with_new_prediction_tags.html">Retrain With New Prediction Tags</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../examples/retrain_with_new_seq2seq_params.html">Retrain With New Seq2Seq Parameters</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../../index.html">deepparse</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../../../index.html" class="icon icon-home"></a> &raquo;</li>
          <li><a href="../../index.html">Module code</a> &raquo;</li>
      <li>deepparse.parser.address_parser</li>
      <li class="wy-breadcrumbs-aside">
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <h1>Source code for deepparse.parser.address_parser</h1><div class="highlight"><pre>
<span></span><span class="kn">import</span> <span class="nn">contextlib</span>
<span class="kn">import</span> <span class="nn">os</span>
<span class="kn">import</span> <span class="nn">re</span>
<span class="kn">import</span> <span class="nn">warnings</span>
<span class="kn">from</span> <span class="nn">typing</span> <span class="kn">import</span> <span class="n">List</span><span class="p">,</span> <span class="n">Union</span><span class="p">,</span> <span class="n">Dict</span><span class="p">,</span> <span class="n">Tuple</span>

<span class="kn">import</span> <span class="nn">poutyne</span>
<span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">from</span> <span class="nn">poutyne.framework</span> <span class="kn">import</span> <span class="n">Experiment</span>
<span class="kn">from</span> <span class="nn">torch.optim</span> <span class="kn">import</span> <span class="n">SGD</span>
<span class="kn">from</span> <span class="nn">torch.utils.data</span> <span class="kn">import</span> <span class="n">DataLoader</span><span class="p">,</span> <span class="n">Subset</span>

<span class="kn">from</span> <span class="nn">.</span> <span class="kn">import</span> <span class="n">formatted_parsed_address</span>
<span class="kn">from</span> <span class="nn">.capturing</span> <span class="kn">import</span> <span class="n">Capturing</span>
<span class="kn">from</span> <span class="nn">.formatted_parsed_address</span> <span class="kn">import</span> <span class="n">FormattedParsedAddress</span>
<span class="kn">from</span> <span class="nn">.tools</span> <span class="kn">import</span> <span class="p">(</span>
    <span class="n">validate_if_new_seq2seq_params</span><span class="p">,</span>
    <span class="n">validate_if_new_prediction_tags</span><span class="p">,</span>
    <span class="n">load_tuple_to_device</span><span class="p">,</span>
    <span class="n">pretrained_parser_in_directory</span><span class="p">,</span>
    <span class="n">get_files_in_directory</span><span class="p">,</span>
    <span class="n">get_address_parser_in_directory</span><span class="p">,</span>
    <span class="n">indices_splitting</span><span class="p">,</span>
    <span class="n">handle_model_name</span><span class="p">,</span>
    <span class="n">infer_model_type</span><span class="p">,</span>
<span class="p">)</span>
<span class="kn">from</span> <span class="nn">..</span> <span class="kn">import</span> <span class="n">validate_data_to_parse</span>
<span class="kn">from</span> <span class="nn">..converter</span> <span class="kn">import</span> <span class="n">TagsConverter</span>
<span class="kn">from</span> <span class="nn">..converter</span> <span class="kn">import</span> <span class="n">fasttext_data_padding</span><span class="p">,</span> <span class="n">bpemb_data_padding</span><span class="p">,</span> <span class="n">DataTransform</span>
<span class="kn">from</span> <span class="nn">..dataset_container</span> <span class="kn">import</span> <span class="n">DatasetContainer</span>
<span class="kn">from</span> <span class="nn">..embeddings_models</span> <span class="kn">import</span> <span class="n">BPEmbEmbeddingsModel</span>
<span class="kn">from</span> <span class="nn">..embeddings_models</span> <span class="kn">import</span> <span class="n">FastTextEmbeddingsModel</span>
<span class="kn">from</span> <span class="nn">..embeddings_models</span> <span class="kn">import</span> <span class="n">MagnitudeEmbeddingsModel</span>
<span class="kn">from</span> <span class="nn">..fasttext_tools</span> <span class="kn">import</span> <span class="n">download_fasttext_embeddings</span>
<span class="kn">from</span> <span class="nn">..fasttext_tools</span> <span class="kn">import</span> <span class="n">download_fasttext_magnitude_embeddings</span>
<span class="kn">from</span> <span class="nn">..metrics</span> <span class="kn">import</span> <span class="n">nll_loss</span><span class="p">,</span> <span class="n">accuracy</span>
<span class="kn">from</span> <span class="nn">..network.bpemb_seq2seq</span> <span class="kn">import</span> <span class="n">BPEmbSeq2SeqModel</span>
<span class="kn">from</span> <span class="nn">..network.fasttext_seq2seq</span> <span class="kn">import</span> <span class="n">FastTextSeq2SeqModel</span>
<span class="kn">from</span> <span class="nn">..preprocessing</span> <span class="kn">import</span> <span class="n">AddressCleaner</span>
<span class="kn">from</span> <span class="nn">..tools</span> <span class="kn">import</span> <span class="n">CACHE_PATH</span>
<span class="kn">from</span> <span class="nn">..vectorizer</span> <span class="kn">import</span> <span class="n">FastTextVectorizer</span><span class="p">,</span> <span class="n">BPEmbVectorizer</span>
<span class="kn">from</span> <span class="nn">..vectorizer</span> <span class="kn">import</span> <span class="n">TrainVectorizer</span>
<span class="kn">from</span> <span class="nn">..vectorizer.magnitude_vectorizer</span> <span class="kn">import</span> <span class="n">MagnitudeVectorizer</span>

<span class="n">_pre_trained_tags_to_idx</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s2">&quot;StreetNumber&quot;</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span>
    <span class="s2">&quot;StreetName&quot;</span><span class="p">:</span> <span class="mi">1</span><span class="p">,</span>
    <span class="s2">&quot;Unit&quot;</span><span class="p">:</span> <span class="mi">2</span><span class="p">,</span>
    <span class="s2">&quot;Municipality&quot;</span><span class="p">:</span> <span class="mi">3</span><span class="p">,</span>
    <span class="s2">&quot;Province&quot;</span><span class="p">:</span> <span class="mi">4</span><span class="p">,</span>
    <span class="s2">&quot;PostalCode&quot;</span><span class="p">:</span> <span class="mi">5</span><span class="p">,</span>
    <span class="s2">&quot;Orientation&quot;</span><span class="p">:</span> <span class="mi">6</span><span class="p">,</span>
    <span class="s2">&quot;GeneralDelivery&quot;</span><span class="p">:</span> <span class="mi">7</span><span class="p">,</span>
    <span class="s2">&quot;EOS&quot;</span><span class="p">:</span> <span class="mi">8</span><span class="p">,</span>  <span class="c1"># the 9th is the EOS with idx 8</span>
<span class="p">}</span>

<span class="c1"># This threshold represents at which point the prediction of the address takes enough time to</span>
<span class="c1"># justify predictions verbosity.</span>
<span class="n">PREDICTION_TIME_PERFORMANCE_THRESHOLD</span> <span class="o">=</span> <span class="mi">64</span>


<div class="viewcode-block" id="AddressParser"><a class="viewcode-back" href="../../../parser.html#deepparse.parser.AddressParser">[docs]</a><span class="k">class</span> <span class="nc">AddressParser</span><span class="p">:</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Address parser to parse an address or a list of address using one of the seq2seq pre-trained</span>
<span class="sd">    networks either with fastText or BPEmb. The default prediction tags are the following</span>

<span class="sd">            - &quot;StreetNumber&quot;: for the street number,</span>
<span class="sd">            - &quot;StreetName&quot;: for the name of the street,</span>
<span class="sd">            - &quot;Unit&quot;: for the unit (such as apartment),</span>
<span class="sd">            - &quot;Municipality&quot;: for the municipality,</span>
<span class="sd">            - &quot;Province&quot;: for the province or local region,</span>
<span class="sd">            - &quot;PostalCode&quot;: for the postal code,</span>
<span class="sd">            - &quot;Orientation&quot;: for the street orientation (e.g. west, east),</span>
<span class="sd">            - &quot;GeneralDelivery&quot;: for other delivery information,</span>
<span class="sd">            - &quot;EOS&quot;: (End Of Sequence) since we use an EOS tag during training, sometimes the models return an EOS tag.</span>

<span class="sd">    Args:</span>
<span class="sd">        model_type (str): The network name to use, can be either:</span>

<span class="sd">            - fasttext (need ~9 GO of RAM to be used),</span>
<span class="sd">            - fasttext-light (need ~2 GO of RAM to be used, but slower than fasttext version),</span>
<span class="sd">            - bpemb (need ~2 GO of RAM to be used),</span>
<span class="sd">            - fastest (quicker to process one address) (equivalent to fasttext),</span>
<span class="sd">            - lightest (the one using the less RAM and GPU usage) (equivalent to fasttext-light),</span>
<span class="sd">            - best (the best accuracy performance) (equivalent to bpemb).</span>

<span class="sd">            The default value is &quot;best&quot; for the most accurate model. Ignored if ``path_to_retrained_model`` is not</span>
<span class="sd">            ``None``. To further improve performance, consider using the models (fasttext or BPEmb) with their</span>
<span class="sd">            counterpart using attention mechanism with the ``attention_mechanism`` flag.</span>
<span class="sd">        attention_mechanism (bool): Whether to use the model with an attention mechanism. The model will use an</span>
<span class="sd">            attention mechanism takes an extra 100 MB on GPU usage (see the doc for more statistics).</span>
<span class="sd">            The default value is False.</span>
<span class="sd">        device (Union[int, str, torch.torch.device]): The device to use can be either:</span>

<span class="sd">            - a ``GPU`` index in int format (e.g. ``0``),</span>
<span class="sd">            - a complete device name in a string format (e.g. ``&#39;cuda:0&#39;``),</span>
<span class="sd">            - a :class:`~torch.torch.device` object,</span>
<span class="sd">            - ``&#39;cpu&#39;`` for a  ``CPU`` use.</span>

<span class="sd">            The default value is GPU with the index ``0`` if it exists, otherwise the value is ``CPU``.</span>
<span class="sd">        rounding (int): The rounding to use when asking the probability of the tags. The default value is 4 digits.</span>
<span class="sd">        verbose (bool): Turn on/off the verbosity of the model weights download and loading. The default value is True.</span>
<span class="sd">        path_to_retrained_model (Union[str, None]): The path to the retrained model to use for prediction. We will</span>
<span class="sd">            `&#39;infer&#39;` the ``model_type`` of the retrained model. Default is None, meaning we use our pre-trained model.</span>
<span class="sd">            If the retrained model uses an attention mechanism, `attention_mechanism` needs to be set to True.</span>

<span class="sd">    Note:</span>
<span class="sd">        For both the networks, we will download the pre-trained weights and embeddings in the ``.cache`` directory</span>
<span class="sd">        for the root user. The pre-trained weights take at most 44 MB. The fastText embeddings take 6.8 GO,</span>
<span class="sd">        the fastText-light embeddings take 3.3 GO and bpemb take 116 MB (in .cache/bpemb).</span>

<span class="sd">        Also, one can download all the dependencies of our pre-trained model using our CLI</span>
<span class="sd">        (e.g. download_model fasttext) before sending it to a node without access to Internet.</span>

<span class="sd">        Here are the URLs to download our pre-trained models directly</span>

<span class="sd">            - `FastText &lt;https://graal.ift.ulaval.ca/public/deepparse/fasttext.ckpt&gt;`_</span>
<span class="sd">            - `BPEmb &lt;https://graal.ift.ulaval.ca/public/deepparse/bpemb.ckpt&gt;`_</span>
<span class="sd">            - `FastText Light &lt;https://graal.ift.ulaval.ca/public/deepparse/fasttext.magnitude.gz&gt;`_.</span>

<span class="sd">    Note:</span>
<span class="sd">        Since Windows uses `spawn` instead of `fork` during multiprocess (for the data loading pre-processing</span>
<span class="sd">        `num_worker` &gt; 0) we use the Gensim model, which takes more RAM (~10 GO) than the Fasttext one (~8 GO).</span>
<span class="sd">        It also takes a longer time to load. See here the</span>
<span class="sd">        `issue &lt;https://github.com/GRAAL-Research/deepparse/issues/89&gt;`_.</span>

<span class="sd">    Note:</span>
<span class="sd">        You may observe a 100% CPU load the first time you call the fasttext-light model. We</span>
<span class="sd">        `hypotheses &lt;https://github.com/GRAAL-Research/deepparse/pull/54#issuecomment-743463855&gt;`_ that this is due</span>
<span class="sd">        to the SQLite database behind `pymagnitude`. This approach create a cache to speed up processing and since the</span>
<span class="sd">        memory mapping is saved between the runs, it&#39;s more intensive the first time you call it and subsequent</span>
<span class="sd">        time this load doesn&#39;t appear.</span>

<span class="sd">    Examples:</span>

<span class="sd">        .. code-block:: python</span>

<span class="sd">            address_parser = AddressParser(device=0) #on gpu device 0</span>
<span class="sd">            parse_address = address_parser(&quot;350 rue des Lilas Ouest Quebec city Quebec G1L 1B6&quot;)</span>

<span class="sd">            address_parser = AddressParser(model_type=&quot;fasttext&quot;, device=&quot;cpu&quot;) # fasttext model on cpu</span>
<span class="sd">            parse_address = address_parser(&quot;350 rue des Lilas Ouest Quebec city Quebec G1L 1B6&quot;)</span>

<span class="sd">        Using a model with attention mechanism</span>

<span class="sd">        .. code-block:: python</span>

<span class="sd">            # fasttext model with attention</span>
<span class="sd">            address_parser = AddressParser(model_type=&quot;fasttext&quot;, attention_mechanism=True)</span>
<span class="sd">            parse_address = address_parser(&quot;350 rue des Lilas Ouest Quebec city Quebec G1L 1B6&quot;)</span>

<span class="sd">        Using a retrained model</span>

<span class="sd">        .. code-block:: python</span>

<span class="sd">            address_parser = AddressParser(model_type=&quot;fasttext&quot;,</span>
<span class="sd">                                           path_to_retrained_model=&#39;/path_to_a_retrain_fasttext_model&#39;)</span>
<span class="sd">            parse_address = address_parser(&quot;350 rue des Lilas Ouest Quebec city Quebec G1L 1B6&quot;)</span>

<span class="sd">        Using a retrained model trained on different tags</span>

<span class="sd">        .. code-block:: python</span>

<span class="sd">            # We don&#39;t give the model_type since it&#39;s ignored when using path_to_retrained_model</span>
<span class="sd">            address_parser = AddressParser(path_to_retrained_model=&#39;/path_to_a_retrain_fasttext_model&#39;)</span>
<span class="sd">            parse_address = address_parser(&quot;350 rue des Lilas Ouest Quebec city Quebec G1L 1B6&quot;)</span>

<span class="sd">        Using a retrained model with attention</span>

<span class="sd">        .. code-block:: python</span>

<span class="sd">            address_parser = AddressParser(model_type=&quot;fasttext&quot;,</span>
<span class="sd">                                           path_to_retrained_model=&#39;/path_to_a_retrain_fasttext_attention_model&#39;,</span>
<span class="sd">                                           attention_mechanism=True)</span>
<span class="sd">            parse_address = address_parser(&quot;350 rue des Lilas Ouest Quebec city Quebec G1L 1B6&quot;)</span>

<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">model_type</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;best&quot;</span><span class="p">,</span>
        <span class="n">attention_mechanism</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
        <span class="n">device</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="nb">str</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">]</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span>
        <span class="n">rounding</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">4</span><span class="p">,</span>
        <span class="n">verbose</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
        <span class="n">path_to_retrained_model</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="kc">None</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="c1"># pylint: disable=too-many-arguments</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_process_device</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">rounding</span> <span class="o">=</span> <span class="n">rounding</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">verbose</span> <span class="o">=</span> <span class="n">verbose</span>

        <span class="c1"># Default pre-trained tag are loaded</span>
        <span class="n">tags_to_idx</span> <span class="o">=</span> <span class="n">_pre_trained_tags_to_idx</span>
        <span class="c1"># Default FIELDS of the formatted address</span>
        <span class="n">fields</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">tags_to_idx</span><span class="p">)</span>
        <span class="c1"># Default new config seq2seq model params</span>
        <span class="n">seq2seq_kwargs</span> <span class="o">=</span> <span class="p">{}</span>  <span class="c1"># Empty for default settings</span>

        <span class="k">if</span> <span class="n">path_to_retrained_model</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">checkpoint_weights</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">path_to_retrained_model</span><span class="p">,</span> <span class="n">map_location</span><span class="o">=</span><span class="s2">&quot;cpu&quot;</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">validate_if_new_seq2seq_params</span><span class="p">(</span><span class="n">checkpoint_weights</span><span class="p">):</span>
                <span class="n">seq2seq_kwargs</span> <span class="o">=</span> <span class="n">checkpoint_weights</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;seq2seq_params&quot;</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">validate_if_new_prediction_tags</span><span class="p">(</span><span class="n">checkpoint_weights</span><span class="p">):</span>
                <span class="c1"># We load the new tags_to_idx</span>
                <span class="n">tags_to_idx</span> <span class="o">=</span> <span class="n">checkpoint_weights</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;prediction_tags&quot;</span><span class="p">)</span>
                <span class="c1"># We change the FIELDS for the FormattedParsedAddress</span>
                <span class="n">fields</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">tags_to_idx</span><span class="p">)</span>

            <span class="c1"># We &quot;infer&quot; the model type, thus we also had to handle the attention_mechanism bool</span>
            <span class="n">model_type</span><span class="p">,</span> <span class="n">attention_mechanism</span> <span class="o">=</span> <span class="n">infer_model_type</span><span class="p">(</span>
                <span class="n">checkpoint_weights</span><span class="p">,</span> <span class="n">attention_mechanism</span><span class="o">=</span><span class="n">attention_mechanism</span>
            <span class="p">)</span>

        <span class="n">formatted_parsed_address</span><span class="o">.</span><span class="n">FIELDS</span> <span class="o">=</span> <span class="n">fields</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">tags_converter</span> <span class="o">=</span> <span class="n">TagsConverter</span><span class="p">(</span><span class="n">tags_to_idx</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">model_type</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_model_type_formatted</span> <span class="o">=</span> <span class="n">handle_model_name</span><span class="p">(</span><span class="n">model_type</span><span class="p">,</span> <span class="n">attention_mechanism</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_model_factory</span><span class="p">(</span>
            <span class="n">verbose</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">verbose</span><span class="p">,</span>
            <span class="n">path_to_retrained_model</span><span class="o">=</span><span class="n">path_to_retrained_model</span><span class="p">,</span>
            <span class="n">prediction_layer_len</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">tags_converter</span><span class="o">.</span><span class="n">dim</span><span class="p">,</span>
            <span class="n">attention_mechanism</span><span class="o">=</span><span class="n">attention_mechanism</span><span class="p">,</span>
            <span class="n">seq2seq_kwargs</span><span class="o">=</span><span class="n">seq2seq_kwargs</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>

    <span class="k">def</span> <span class="fm">__str__</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">str</span><span class="p">:</span>
        <span class="k">return</span> <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">_model_type_formatted</span><span class="si">}</span><span class="s2">AddressParser&quot;</span>

    <span class="fm">__repr__</span> <span class="o">=</span> <span class="fm">__str__</span>  <span class="c1"># to call __str__ when list of address</span>

<div class="viewcode-block" id="AddressParser.__call__"><a class="viewcode-back" href="../../../parser.html#deepparse.parser.AddressParser.__call__">[docs]</a>    <span class="k">def</span> <span class="fm">__call__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">addresses_to_parse</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">],</span> <span class="nb">str</span><span class="p">,</span> <span class="n">DatasetContainer</span><span class="p">],</span>
        <span class="n">with_prob</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
        <span class="n">batch_size</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">32</span><span class="p">,</span>
        <span class="n">num_workers</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Union</span><span class="p">[</span><span class="n">FormattedParsedAddress</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="n">FormattedParsedAddress</span><span class="p">]]:</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Callable method to parse the components of an address or a list of address.</span>

<span class="sd">        Args:</span>
<span class="sd">            addresses_to_parse (Union[list[str], str, ~deepparse.dataset_container.DatasetContainer]): The addresses to</span>
<span class="sd">                be parsed, can be either a single address (when using str), a list of address or a DatasetContainer.</span>
<span class="sd">                We apply some validation tests before parsing to validate its content if the data to parse is a string</span>
<span class="sd">                or a list of strings. We apply the following basic criteria:</span>

<span class="sd">                    - no addresses are None value,</span>
<span class="sd">                    - no addresses are empty string, and</span>
<span class="sd">                    - no addresses are whitespace-only strings.</span>

<span class="sd">                When using a list of addresses, the addresses are processed in batch, allowing a faster process.</span>
<span class="sd">                For example, using fastText model, a single address takes around 0.003 seconds to be parsed using a</span>
<span class="sd">                batch of 1 (1 element at the time is processed). This time can be reduced to 0.00035 seconds per</span>
<span class="sd">                address when using a batch of 128 (128 elements at the time are processed).</span>
<span class="sd">            with_prob (bool): If true, return the probability of all the tags with the specified</span>
<span class="sd">                rounding.</span>
<span class="sd">            batch_size (int): The size of the batch (default is 32).</span>
<span class="sd">            num_workers (int): Number of workers to use for the data loader (default is 0, which means that the data</span>
<span class="sd">                will be loaded in the main process.).</span>

<span class="sd">        Return:</span>
<span class="sd">            Either a :class:`~FormattedParsedAddress` or a list of</span>
<span class="sd">            :class:`~FormattedParsedAddress` when given more than one address.</span>

<span class="sd">        Examples:</span>

<span class="sd">            .. code-block:: python</span>

<span class="sd">                address_parser = AddressParser(device=0)  # on gpu device 0</span>
<span class="sd">                parse_address = address_parser(&quot;350 rue des Lilas Ouest Quebec city Quebec G1L 1B6&quot;)</span>

<span class="sd">                # It also can be a list of addresses</span>
<span class="sd">                parse_address = address_parser([&quot;350 rue des Lilas Ouest Quebec city Quebec G1L 1B6&quot;,</span>
<span class="sd">                                                &quot;350 rue des Lilas Ouest Quebec city Quebec G1L 1B6&quot;])</span>

<span class="sd">                # It can also output the prob of the predictions</span>
<span class="sd">                parse_address = address_parser(&quot;350 rue des Lilas Ouest Quebec city Quebec G1L 1B6&quot;,</span>
<span class="sd">                                               with_prob=True)</span>

<span class="sd">                # Print the parsed address</span>
<span class="sd">                print(parsed_address)</span>

<span class="sd">            Using a larger batch size</span>

<span class="sd">            .. code-block:: python</span>

<span class="sd">                address_parser = AddressParser(device=0) #on gpu device 0</span>
<span class="sd">                parse_address = address_parser(a_large_list_dataset, batch_size=1024)</span>

<span class="sd">                # You can also use more worker</span>
<span class="sd">                parse_address = address_parser(a_large_list_dataset, batch_size=1024, num_workers=2)</span>


<span class="sd">            Or using one of our dataset container</span>

<span class="sd">            .. code-block:: python</span>

<span class="sd">                addresses_to_parse = CSVDatasetContainer(&quot;./a_path.csv&quot;, column_names=[&quot;address_column_name&quot;],</span>
<span class="sd">                                                         is_training_container=False)</span>
<span class="sd">                address_parser(addresses_to_parse)</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">addresses_to_parse</span><span class="p">,</span> <span class="nb">str</span><span class="p">):</span>
            <span class="n">addresses_to_parse</span> <span class="o">=</span> <span class="p">[</span><span class="n">addresses_to_parse</span><span class="p">]</span>

        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">addresses_to_parse</span><span class="p">,</span> <span class="n">List</span><span class="p">):</span>
            <span class="n">validate_data_to_parse</span><span class="p">(</span><span class="n">addresses_to_parse</span><span class="p">)</span>

        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">addresses_to_parse</span><span class="p">,</span> <span class="n">DatasetContainer</span><span class="p">):</span>
            <span class="n">addresses_to_parse</span> <span class="o">=</span> <span class="n">addresses_to_parse</span><span class="o">.</span><span class="n">data</span>

        <span class="n">clean_addresses</span> <span class="o">=</span> <span class="n">AddressCleaner</span><span class="p">()</span><span class="o">.</span><span class="n">clean</span><span class="p">(</span><span class="n">addresses_to_parse</span><span class="p">)</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">verbose</span> <span class="ow">and</span> <span class="nb">len</span><span class="p">(</span><span class="n">addresses_to_parse</span><span class="p">)</span> <span class="o">&gt;</span> <span class="n">PREDICTION_TIME_PERFORMANCE_THRESHOLD</span><span class="p">:</span>
            <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Vectorizing the address&quot;</span><span class="p">)</span>

        <span class="n">predict_data_loader</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span>
            <span class="n">clean_addresses</span><span class="p">,</span>
            <span class="n">collate_fn</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_predict_pipeline</span><span class="p">,</span>
            <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span>
            <span class="n">num_workers</span><span class="o">=</span><span class="n">num_workers</span><span class="p">,</span>
        <span class="p">)</span>

        <span class="n">tags_predictions</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">tags_predictions_prob</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">predict_data_loader</span><span class="p">:</span>
            <span class="n">tensor_prediction</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">(</span><span class="o">*</span><span class="n">load_tuple_to_device</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">))</span>
            <span class="n">tags_predictions</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="n">tensor_prediction</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="mi">2</span><span class="p">)[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span><span class="o">.</span><span class="n">tolist</span><span class="p">())</span>
            <span class="n">tags_predictions_prob</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span>
                <span class="n">torch</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">tensor_prediction</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="mi">2</span><span class="p">)[</span><span class="mi">0</span><span class="p">])</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span><span class="o">.</span><span class="n">tolist</span><span class="p">()</span>
            <span class="p">)</span>

        <span class="n">tagged_addresses_components</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_fill_tagged_addresses_components</span><span class="p">(</span>
            <span class="n">tags_predictions</span><span class="p">,</span>
            <span class="n">tags_predictions_prob</span><span class="p">,</span>
            <span class="n">addresses_to_parse</span><span class="p">,</span>
            <span class="n">clean_addresses</span><span class="p">,</span>
            <span class="n">with_prob</span><span class="p">,</span>
        <span class="p">)</span>

        <span class="k">return</span> <span class="n">tagged_addresses_components</span></div>

<div class="viewcode-block" id="AddressParser.retrain"><a class="viewcode-back" href="../../../parser.html#deepparse.parser.AddressParser.retrain">[docs]</a>    <span class="k">def</span> <span class="nf">retrain</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">dataset_container</span><span class="p">:</span> <span class="n">DatasetContainer</span><span class="p">,</span>
        <span class="n">train_ratio</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.8</span><span class="p">,</span>
        <span class="n">batch_size</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">32</span><span class="p">,</span>
        <span class="n">epochs</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">5</span><span class="p">,</span>
        <span class="n">num_workers</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span>
        <span class="n">learning_rate</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.01</span><span class="p">,</span>
        <span class="n">callbacks</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="n">List</span><span class="p">,</span> <span class="kc">None</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">seed</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">42</span><span class="p">,</span>
        <span class="n">logging_path</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;./checkpoints&quot;</span><span class="p">,</span>
        <span class="n">disable_tensorboard</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
        <span class="n">prediction_tags</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="n">Dict</span><span class="p">,</span> <span class="kc">None</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">seq2seq_params</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="n">Dict</span><span class="p">,</span> <span class="kc">None</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">layers_to_freeze</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="kc">None</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">List</span><span class="p">[</span><span class="n">Dict</span><span class="p">]:</span>
        <span class="c1"># pylint: disable=too-many-arguments, line-too-long, too-many-locals, too-many-branches, too-many-statements</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Method to retrain the address parser model using a dataset with the same tags. We train using</span>
<span class="sd">        `experiment &lt;https://poutyne.org/experiment.html&gt;`_ from `poutyne &lt;https://poutyne.org/index.html&gt;`_</span>
<span class="sd">        framework. The experiment module allows us to save checkpoints (``ckpt``, in a pickle format) and a log.tsv</span>
<span class="sd">        where the best epochs can be found (the best epoch is used for the test). The retrained model file name are</span>
<span class="sd">        formatted as ``retrained_{model_type}_address_parser.ckpt``. For example, if you retrain a fasttext model,</span>
<span class="sd">        the file name will be ``retrained_fasttext_address_parser.ckpt``. The retrained saved model included, in a</span>
<span class="sd">        dictionary format, the model weights, the model type, if new ``prediction_tags`` were used, the new</span>
<span class="sd">        prediction tags, and if new ``seq2seq_params`` were used, the new seq2seq parameters.</span>

<span class="sd">        Args:</span>
<span class="sd">            dataset_container (~deepparse.dataset_container.DatasetContainer): The dataset container of the data to use</span>
<span class="sd">                such as any PyTorch Dataset (:class:`~torch.utils.data.Dataset`) user define class or one of our two</span>
<span class="sd">                DatasetContainer (:class:`~deepparse.dataset_container.PickleDatasetContainer` or</span>
<span class="sd">                :class:`~deepparse.dataset_container.CSVDatasetContainer`)</span>
<span class="sd">            train_ratio (float): The ratio to use of the dataset for the training. The rest of the data is used for the</span>
<span class="sd">                validation (e.g. a train ratio of 0.8 mean a 80-20 train-valid split) (default is 0.8).</span>
<span class="sd">            batch_size (int): The size of the batch (default is 32).</span>
<span class="sd">            epochs (int): number of training epochs (default is 5).</span>
<span class="sd">            num_workers (int): Number of workers to use for the data loader (default is 1 worker).</span>
<span class="sd">            learning_rate (float): The learning rate (LR) to use for training (default 0.01).</span>
<span class="sd">            callbacks (Union[list, None]): List of callbacks to use during training.</span>
<span class="sd">                See Poutyne `callback &lt;https://poutyne.org/callbacks.html#callback-class&gt;`_ for more information. By</span>
<span class="sd">                default, we set no callback.</span>
<span class="sd">            seed (int): Seed to use (by default 42).</span>
<span class="sd">            logging_path (str): The logging path for the checkpoints. Poutyne will use the best one and reload the</span>
<span class="sd">                state if any checkpoints are there. Thus, an error will be raised if you change the model type.</span>
<span class="sd">                For example,  you retrain a FastText model and then retrain a BPEmb in the same logging path directory.</span>
<span class="sd">                By default, the path is ``./checkpoints``.</span>
<span class="sd">            disable_tensorboard (bool): To disable Poutyne automatic Tensorboard monitoring. By default, we disable them</span>
<span class="sd">                (true).</span>
<span class="sd">            prediction_tags (Union[dict, None]): A dictionary where the keys are the address components</span>
<span class="sd">                (e.g. street name) and the values are the components indices (from 0 to N + 1) to use during retraining</span>
<span class="sd">                of a model. The ``+ 1`` corresponds to the End Of Sequence (EOS) token that needs to be included in the</span>
<span class="sd">                dictionary. We will use the length of this dictionary for the output size of the prediction layer.</span>
<span class="sd">                We also save the dictionary to be used later on when you load the model. Default is None, meaning</span>
<span class="sd">                we use our pre-trained model prediction tags.</span>
<span class="sd">            seq2seq_params (Union[dict, None]): A dictionary of seq2seq parameters to modify the seq2seq architecture</span>
<span class="sd">                to train. Note that if you change the seq2seq parameters, a new model will be trained from scratch.</span>
<span class="sd">                Parameters that can be modified are:</span>

<span class="sd">                    - The ``input_size`` of the encoder (i.e. the embeddings size). The default value is 300.</span>
<span class="sd">                    - The size of the ``encoder_hidden_size`` of the encoder. The default value is 1024.</span>
<span class="sd">                    - The number of ``encoder_num_layers`` of the encoder. The default value is 1.</span>
<span class="sd">                    - The size of the ``decoder_hidden_size`` of the decoder. The default value is 1024.</span>
<span class="sd">                    - The number of ``decoder_num_layers`` of the decoder. The default value is 1.</span>
<span class="sd">                Default is None, meaning we use the default seq2seq architecture.</span>
<span class="sd">            layers_to_freeze (Union[str, None]): Name of the portion of the seq2seq to freeze layers,</span>
<span class="sd">                thus reducing the number of parameters to learn. Will be ignored if ``seq2seq_params`` is not None.</span>
<span class="sd">                Possible freezing settings are:</span>

<span class="sd">                    - ``None``: No layers are frozen.</span>
<span class="sd">                    - &#39;encoder&#39;: To freeze the encoder part of the seq2seq. That is the part that encodes the address</span>
<span class="sd">                    into a more dense representation.</span>
<span class="sd">                    - &#39;decoder&#39;: To freeze the decoder part of the seq2seq. That is the part that decodes a dense</span>
<span class="sd">                    address representation.</span>
<span class="sd">                    - &#39;prediction_layer&#39;: To freeze the last layer that predicts a tag class (i.e. a fully connected</span>
<span class="sd">                    with an output size of the same length as the prediction tags).</span>
<span class="sd">                    - &#39;seq2seq&#39;: To freeze the encoder and decoder but **not** the prediction layer.</span>

<span class="sd">               Default is ``None``, meaning we do not freeze any layers.</span>

<span class="sd">        Return:</span>
<span class="sd">            A list of dictionary with the best epoch stats (see `Experiment class</span>
<span class="sd">            &lt;https://poutyne.org/experiment.html#poutyne.Experiment.train&gt;`_ for details).</span>

<span class="sd">        Note:</span>
<span class="sd">            We recommend using a learning rate scheduler procedure during retraining to reduce the chance</span>
<span class="sd">            of losing too much of our learned weights, thus increasing retraining time. We</span>
<span class="sd">            personally use the following ``poutyne.StepLR(step_size=1, gamma=0.1)``.</span>
<span class="sd">            Also, starting learning rate should be relatively low (i.e. 0.01 or lower).</span>

<span class="sd">        Note:</span>
<span class="sd">            We use SGD optimizer, NLL loss and accuracy as a metric, the data is shuffled, and we use teacher forcing</span>
<span class="sd">            during training (with a prob of 0.5) as in the `article &lt;https://arxiv.org/abs/2006.16152&gt;`_.</span>

<span class="sd">        Note:</span>
<span class="sd">            Due to pymagnitude, we could not train using the Magnitude embeddings, meaning it&#39;s not possible to</span>
<span class="sd">            train using the fasttext-light model. But, since we don&#39;t update the embeddings weights, one can retrain</span>
<span class="sd">            using the fasttext model and later on use the weights with the fasttext-light.</span>

<span class="sd">        Note:</span>
<span class="sd">            When retraining a model, Poutyne will create checkpoints. After the training, we use the best checkpoint</span>
<span class="sd">            in a directory as the model to load. Thus, if you train two different models in the same directory,</span>
<span class="sd">            the second retrain will not work due to model differences.</span>

<span class="sd">        Examples:</span>

<span class="sd">            .. code-block:: python</span>

<span class="sd">                address_parser = AddressParser(device=0) #on gpu device 0</span>
<span class="sd">                data_path = &#39;path_to_a_pickle_dataset.p&#39;</span>

<span class="sd">                container = PickleDatasetContainer(data_path)</span>

<span class="sd">                address_parser.retrain(container, 0.8, epochs=1, batch_size=128)</span>

<span class="sd">            Using the freezing layers parameters to freeze layers during training</span>

<span class="sd">            .. code-block:: python</span>

<span class="sd">                address_parser = AddressParser(device=0)</span>
<span class="sd">                data_path = &#39;path_to_a_csv_dataset.p&#39;</span>

<span class="sd">                container = CSVDatasetContainer(data_path)</span>
<span class="sd">                address_parser.retrain(container, 0.8, epochs=5, batch_size=128, layers_to_freeze=&quot;encoder&quot;)</span>

<span class="sd">            Using learning rate scheduler callback.</span>

<span class="sd">            .. code-block:: python</span>

<span class="sd">                import poutyne</span>

<span class="sd">                address_parser = AddressParser(device=0)</span>
<span class="sd">                data_path = &#39;path_to_a_csv_dataset.p&#39;</span>

<span class="sd">                container = CSVDatasetContainer(data_path)</span>

<span class="sd">                lr_scheduler = poutyne.StepLR(step_size=1, gamma=0.1) # reduce LR by a factor of 10 each epoch</span>
<span class="sd">                address_parser.retrain(container, 0.8, epochs=5, batch_size=128, callbacks=[lr_scheduler])</span>

<span class="sd">            Using your own prediction tags dictionary.</span>

<span class="sd">            .. code-block:: python</span>

<span class="sd">                address_components = {&quot;ATag&quot;:0, &quot;AnotherTag&quot;: 1, &quot;EOS&quot;: 2}</span>

<span class="sd">                address_parser = AddressParser(device=0) #on gpu device 0</span>
<span class="sd">                data_path = &#39;path_to_a_pickle_dataset.p&#39;</span>

<span class="sd">                container = PickleDatasetContainer(data_path)</span>

<span class="sd">                address_parser.retrain(container, 0.8, epochs=1, batch_size=128, prediction_tags=address_components)</span>

<span class="sd">            Using your own seq2seq parameters.</span>

<span class="sd">            .. code-block:: python</span>

<span class="sd">                seq2seq_params = {&quot;encoder_hidden_size&quot;: 512, &quot;decoder_hidden_size&quot;: 512}</span>

<span class="sd">                address_parser = AddressParser(device=0) #on gpu device 0</span>
<span class="sd">                data_path = &#39;path_to_a_pickle_dataset.p&#39;</span>

<span class="sd">                container = PickleDatasetContainer(data_path)</span>

<span class="sd">                address_parser.retrain(container, 0.8, epochs=1, batch_size=128, seq2seq_params=seq2seq_params)</span>


<span class="sd">            Using your own seq2seq parameters and prediction tags dictionary.</span>

<span class="sd">            .. code-block:: python</span>

<span class="sd">                seq2seq_params = {&quot;encoder_hidden_size&quot;: 512, &quot;decoder_hidden_size&quot;: 512}</span>
<span class="sd">                address_components = {&quot;ATag&quot;:0, &quot;AnotherTag&quot;: 1, &quot;EOS&quot;: 2}</span>

<span class="sd">                address_parser = AddressParser(device=0) #on gpu device 0</span>
<span class="sd">                data_path = &#39;path_to_a_pickle_dataset.p&#39;</span>

<span class="sd">                container = PickleDatasetContainer(data_path)</span>

<span class="sd">                address_parser.retrain(container, 0.8, epochs=1, batch_size=128, seq2seq_params=seq2seq_params,</span>
<span class="sd">                    prediction_tags=address_components)</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="s2">&quot;fasttext-light&quot;</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">model_type</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;It&#39;s not possible to retrain a fasttext-light due to pymagnitude problem.&quot;</span><span class="p">)</span>

        <span class="k">if</span> <span class="ow">not</span> <span class="n">dataset_container</span><span class="o">.</span><span class="n">is_a_train_container</span><span class="p">():</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;The dataset container is not a train container.&quot;</span><span class="p">)</span>

        <span class="n">model_factory_dict</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;prediction_layer_len&quot;</span><span class="p">:</span> <span class="mi">9</span><span class="p">}</span>  <span class="c1"># We set the default output dim size</span>

        <span class="k">if</span> <span class="n">prediction_tags</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="c1"># Handle prediction tags</span>
            <span class="k">if</span> <span class="s2">&quot;EOS&quot;</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">prediction_tags</span><span class="o">.</span><span class="n">keys</span><span class="p">():</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;The prediction tags dictionary is missing the EOS tag.&quot;</span><span class="p">)</span>

            <span class="n">fields</span> <span class="o">=</span> <span class="p">[</span><span class="n">field</span> <span class="k">for</span> <span class="n">field</span> <span class="ow">in</span> <span class="n">prediction_tags</span> <span class="k">if</span> <span class="n">field</span> <span class="o">!=</span> <span class="s2">&quot;EOS&quot;</span><span class="p">]</span>
            <span class="n">formatted_parsed_address</span><span class="o">.</span><span class="n">FIELDS</span> <span class="o">=</span> <span class="n">fields</span>

            <span class="bp">self</span><span class="o">.</span><span class="n">tags_converter</span> <span class="o">=</span> <span class="n">TagsConverter</span><span class="p">(</span><span class="n">prediction_tags</span><span class="p">)</span>

            <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">same_output_dim</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">tags_converter</span><span class="o">.</span><span class="n">dim</span><span class="p">):</span>
                <span class="c1"># Since we have change the output layer dim, we need to handle the prediction layer dim</span>
                <span class="n">new_dim</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">tags_converter</span><span class="o">.</span><span class="n">dim</span>
                <span class="k">if</span> <span class="n">seq2seq_params</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">handle_new_output_dim</span><span class="p">(</span><span class="n">new_dim</span><span class="p">)</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="c1"># We update the output dim size</span>
                    <span class="n">model_factory_dict</span><span class="o">.</span><span class="n">update</span><span class="p">({</span><span class="s2">&quot;prediction_layer_len&quot;</span><span class="p">:</span> <span class="n">new_dim</span><span class="p">})</span>

        <span class="k">if</span> <span class="n">seq2seq_params</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="c1"># Handle seq2seq params</span>
            <span class="c1"># We set the flag to use the pre-trained weights to false since we train new ones</span>
            <span class="n">seq2seq_params</span><span class="o">.</span><span class="n">update</span><span class="p">({</span><span class="s2">&quot;pre_trained_weights&quot;</span><span class="p">:</span> <span class="kc">False</span><span class="p">})</span>

            <span class="n">model_factory_dict</span><span class="o">.</span><span class="n">update</span><span class="p">({</span><span class="s2">&quot;seq2seq_kwargs&quot;</span><span class="p">:</span> <span class="n">seq2seq_params</span><span class="p">})</span>
            <span class="c1"># We set verbose to false since model is reloaded</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_model_factory</span><span class="p">(</span><span class="n">verbose</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">path_to_retrained_model</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="o">**</span><span class="n">model_factory_dict</span><span class="p">)</span>

        <span class="n">callbacks</span> <span class="o">=</span> <span class="p">[]</span> <span class="k">if</span> <span class="n">callbacks</span> <span class="ow">is</span> <span class="kc">None</span> <span class="k">else</span> <span class="n">callbacks</span>
        <span class="n">train_generator</span><span class="p">,</span> <span class="n">valid_generator</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_create_training_data_generator</span><span class="p">(</span>
            <span class="n">dataset_container</span><span class="p">,</span> <span class="n">train_ratio</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">,</span> <span class="n">num_workers</span><span class="p">,</span> <span class="n">seed</span><span class="o">=</span><span class="n">seed</span>
        <span class="p">)</span>

        <span class="k">if</span> <span class="n">layers_to_freeze</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">seq2seq_params</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="c1"># We ignore the layers to freeze if seq2seq_params is not None</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_freeze_model_params</span><span class="p">(</span><span class="n">layers_to_freeze</span><span class="p">)</span>

        <span class="n">optimizer</span> <span class="o">=</span> <span class="n">SGD</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">learning_rate</span><span class="p">)</span>

        <span class="n">exp</span> <span class="o">=</span> <span class="n">Experiment</span><span class="p">(</span>
            <span class="n">logging_path</span><span class="p">,</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">,</span>
            <span class="n">device</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">,</span>
            <span class="n">optimizer</span><span class="o">=</span><span class="n">optimizer</span><span class="p">,</span>
            <span class="n">loss_function</span><span class="o">=</span><span class="n">nll_loss</span><span class="p">,</span>
            <span class="n">batch_metrics</span><span class="o">=</span><span class="p">[</span><span class="n">accuracy</span><span class="p">],</span>
        <span class="p">)</span>

        <span class="k">try</span><span class="p">:</span>
            <span class="n">with_capturing_context</span> <span class="o">=</span> <span class="kc">False</span>
            <span class="k">if</span> <span class="nb">float</span><span class="p">(</span><span class="s2">&quot;.&quot;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="nb">str</span><span class="p">(</span><span class="n">poutyne</span><span class="o">.</span><span class="n">version</span><span class="o">.</span><span class="n">__version__</span><span class="p">)</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s2">&quot;.&quot;</span><span class="p">)[:</span><span class="mi">2</span><span class="p">]))</span> <span class="o">&lt;</span> <span class="mf">1.8</span><span class="p">:</span>
                <span class="nb">print</span><span class="p">(</span>
                    <span class="s2">&quot;You are using a older version of Poutyne that does not support properly error management.&quot;</span>
                    <span class="s2">&quot; Due to that, we cannot show retrain progress. To fix that, update Poutyne to &quot;</span>
                    <span class="s2">&quot;the newest version.&quot;</span>
                <span class="p">)</span>
                <span class="n">with_capturing_context</span> <span class="o">=</span> <span class="kc">True</span>
            <span class="n">train_res</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_retrain</span><span class="p">(</span>
                <span class="n">experiment</span><span class="o">=</span><span class="n">exp</span><span class="p">,</span>
                <span class="n">train_generator</span><span class="o">=</span><span class="n">train_generator</span><span class="p">,</span>
                <span class="n">valid_generator</span><span class="o">=</span><span class="n">valid_generator</span><span class="p">,</span>
                <span class="n">epochs</span><span class="o">=</span><span class="n">epochs</span><span class="p">,</span>
                <span class="n">seed</span><span class="o">=</span><span class="n">seed</span><span class="p">,</span>
                <span class="n">callbacks</span><span class="o">=</span><span class="n">callbacks</span><span class="p">,</span>
                <span class="n">disable_tensorboard</span><span class="o">=</span><span class="n">disable_tensorboard</span><span class="p">,</span>
                <span class="n">capturing_context</span><span class="o">=</span><span class="n">with_capturing_context</span><span class="p">,</span>
            <span class="p">)</span>
        <span class="k">except</span> <span class="ne">RuntimeError</span> <span class="k">as</span> <span class="n">error</span><span class="p">:</span>
            <span class="n">list_of_file_path</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">listdir</span><span class="p">(</span><span class="n">path</span><span class="o">=</span><span class="s2">&quot;.&quot;</span><span class="p">)</span>
            <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">list_of_file_path</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
                <span class="k">if</span> <span class="n">pretrained_parser_in_directory</span><span class="p">(</span><span class="n">logging_path</span><span class="p">):</span>
                    <span class="c1"># Mean we might already have checkpoint in the training directory</span>
                    <span class="n">files_in_directory</span> <span class="o">=</span> <span class="n">get_files_in_directory</span><span class="p">(</span><span class="n">logging_path</span><span class="p">)</span>
                    <span class="n">retrained_address_parser_in_directory</span> <span class="o">=</span> <span class="n">get_address_parser_in_directory</span><span class="p">(</span><span class="n">files_in_directory</span><span class="p">)[</span>
                        <span class="mi">0</span>
                    <span class="p">]</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s2">&quot;_&quot;</span><span class="p">)[</span><span class="mi">1</span><span class="p">]</span>
                    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">model_type</span> <span class="o">!=</span> <span class="n">retrained_address_parser_in_directory</span><span class="p">:</span>
                        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                            <span class="sa">f</span><span class="s2">&quot;You are currently training a </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">model_type</span><span class="si">}</span><span class="s2"> in the directory &quot;</span>
                            <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">logging_path</span><span class="si">}</span><span class="s2"> where a different retrained &quot;</span>
                            <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">retrained_address_parser_in_directory</span><span class="si">}</span><span class="s2"> is currently his.&quot;</span>
                            <span class="sa">f</span><span class="s2">&quot; Thus, the loading of the model is failing. Change directory to retrain the&quot;</span>
                            <span class="sa">f</span><span class="s2">&quot; </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">model_type</span><span class="si">}</span><span class="s2">.&quot;</span>
                        <span class="p">)</span> <span class="kn">from</span> <span class="nn">error</span>
                    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">model_type</span> <span class="o">==</span> <span class="n">retrained_address_parser_in_directory</span><span class="p">:</span>
                        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                            <span class="sa">f</span><span class="s2">&quot;You are currently training a different </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">model_type</span><span class="si">}</span><span class="s2"> version from&quot;</span>
                            <span class="sa">f</span><span class="s2">&quot; the one in the </span><span class="si">{</span><span class="n">logging_path</span><span class="si">}</span><span class="s2">. Verify version.&quot;</span>
                        <span class="p">)</span> <span class="kn">from</span> <span class="nn">error</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span><span class="n">error</span><span class="o">.</span><span class="n">args</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span> <span class="kn">from</span> <span class="nn">error</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">file_path</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">logging_path</span><span class="p">,</span> <span class="sa">f</span><span class="s2">&quot;retrained_</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">model_type</span><span class="si">}</span><span class="s2">_address_parser.ckpt&quot;</span><span class="p">)</span>
            <span class="n">torch_save</span> <span class="o">=</span> <span class="p">{</span>
                <span class="s2">&quot;address_tagger_model&quot;</span><span class="p">:</span> <span class="n">exp</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">network</span><span class="o">.</span><span class="n">state_dict</span><span class="p">(),</span>
                <span class="s2">&quot;model_type&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">model_type</span><span class="p">,</span>
            <span class="p">}</span>
            <span class="k">if</span> <span class="n">seq2seq_params</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                <span class="c1"># Means we have changed the seq2seq params</span>
                <span class="n">torch_save</span><span class="o">.</span><span class="n">update</span><span class="p">({</span><span class="s2">&quot;seq2seq_params&quot;</span><span class="p">:</span> <span class="n">seq2seq_params</span><span class="p">})</span>
            <span class="k">if</span> <span class="n">prediction_tags</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                <span class="c1">#  Means we have changed the predictions tags</span>
                <span class="n">torch_save</span><span class="o">.</span><span class="n">update</span><span class="p">({</span><span class="s2">&quot;prediction_tags&quot;</span><span class="p">:</span> <span class="n">prediction_tags</span><span class="p">})</span>

            <span class="n">torch</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">torch_save</span><span class="p">,</span> <span class="n">file_path</span><span class="p">)</span>
            <span class="k">return</span> <span class="n">train_res</span></div>

<div class="viewcode-block" id="AddressParser.test"><a class="viewcode-back" href="../../../parser.html#deepparse.parser.AddressParser.test">[docs]</a>    <span class="k">def</span> <span class="nf">test</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">test_dataset_container</span><span class="p">:</span> <span class="n">DatasetContainer</span><span class="p">,</span>
        <span class="n">batch_size</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">32</span><span class="p">,</span>
        <span class="n">num_workers</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span>
        <span class="n">callbacks</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="n">List</span><span class="p">,</span> <span class="kc">None</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">seed</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">42</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Dict</span><span class="p">:</span>
        <span class="c1"># pylint: disable=too-many-arguments, too-many-locals</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Method to test a retrained or a pre-trained model using a dataset with the default tags. If you test a</span>
<span class="sd">        retrained model with different prediction tags, we will use those tags.</span>

<span class="sd">        Args:</span>
<span class="sd">            test_dataset_container (~deepparse.dataset_container.DatasetContainer):</span>
<span class="sd">                The test dataset container of the data to use.</span>
<span class="sd">            batch_size (int): The size of the batch (default is 32).</span>
<span class="sd">            num_workers (int): Number of workers to use for the data loader (default is 1 worker).</span>
<span class="sd">            callbacks (Union[list, None]): List of callbacks to use during training.</span>
<span class="sd">                See Poutyne `callback &lt;https://poutyne.org/callbacks.html#callback-class&gt;`_ for more information.</span>
<span class="sd">                By default, we set no callback.</span>
<span class="sd">            seed (int): Seed to use (by default 42).</span>
<span class="sd">            callbacks (Union[list, None]): List of callbacks to use during training.</span>
<span class="sd">                See Poutyne `callback &lt;https://poutyne.org/callbacks.html#callback-class&gt;`_ for more information.</span>
<span class="sd">                By default, we set no callback.</span>
<span class="sd">        Return:</span>
<span class="sd">            A dictionary with the stats (see `Experiment class</span>
<span class="sd">            &lt;https://poutyne.org/experiment.html#poutyne.Experiment.train&gt;`_ for details).</span>

<span class="sd">        Note:</span>
<span class="sd">            We use NLL loss and accuracy as in the `article &lt;https://arxiv.org/abs/2006.16152&gt;`_.</span>

<span class="sd">        Examples:</span>

<span class="sd">            .. code-block:: python</span>

<span class="sd">                address_parser = AddressParser(device=0) #on gpu device 0</span>
<span class="sd">                data_path = &#39;path_to_a_pickle_test_dataset.p&#39;</span>

<span class="sd">                test_container = PickleDatasetContainer(data_path, is_training_container=False)</span>

<span class="sd">                address_parser.test(test_container) # We test the model on the data</span>

<span class="sd">            You can also test your fine-tuned model</span>

<span class="sd">            .. code-block:: python</span>

<span class="sd">                address_components = {&quot;ATag&quot;:0, &quot;AnotherTag&quot;: 1, &quot;EOS&quot;: 2}</span>

<span class="sd">                address_parser = AddressParser(device=0) #on gpu device 0</span>

<span class="sd">                # Train phase</span>
<span class="sd">                data_path = &#39;path_to_a_pickle_train_dataset.p&#39;</span>

<span class="sd">                train_container = PickleDatasetContainer(data_path)</span>

<span class="sd">                address_parser.retrain(container, 0.8, epochs=1, batch_size=128, prediction_tags=address_components)</span>

<span class="sd">                # Test phase</span>
<span class="sd">                data_path = &#39;path_to_a_pickle_test_dataset.p&#39;</span>

<span class="sd">                test_container = PickleDatasetContainer(data_path, is_training_container=False)</span>

<span class="sd">                address_parser.test(test_container) # Test the retrained model</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="s2">&quot;fasttext-light&quot;</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">model_type</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="s2">&quot;It&#39;s not possible to test a fasttext-light due to pymagnitude problem. See Retrain method&quot;</span>
                <span class="s2">&quot;doc for more details.&quot;</span>
            <span class="p">)</span>

        <span class="k">if</span> <span class="ow">not</span> <span class="n">test_dataset_container</span><span class="o">.</span><span class="n">is_a_train_container</span><span class="p">():</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;The dataset container is not a train container.&quot;</span><span class="p">)</span>

        <span class="n">callbacks</span> <span class="o">=</span> <span class="p">[]</span> <span class="k">if</span> <span class="n">callbacks</span> <span class="ow">is</span> <span class="kc">None</span> <span class="k">else</span> <span class="n">callbacks</span>
        <span class="n">data_transform</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_set_data_transformer</span><span class="p">()</span>

        <span class="n">test_generator</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span>
            <span class="n">test_dataset_container</span><span class="p">,</span>
            <span class="n">collate_fn</span><span class="o">=</span><span class="n">data_transform</span><span class="o">.</span><span class="n">output_transform</span><span class="p">,</span>
            <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span>
            <span class="n">num_workers</span><span class="o">=</span><span class="n">num_workers</span><span class="p">,</span>
        <span class="p">)</span>

        <span class="n">exp</span> <span class="o">=</span> <span class="n">Experiment</span><span class="p">(</span>
            <span class="s2">&quot;./checkpoint&quot;</span><span class="p">,</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">,</span>
            <span class="n">device</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">,</span>
            <span class="n">loss_function</span><span class="o">=</span><span class="n">nll_loss</span><span class="p">,</span>
            <span class="n">batch_metrics</span><span class="o">=</span><span class="p">[</span><span class="n">accuracy</span><span class="p">],</span>
            <span class="n">logging</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
        <span class="p">)</span>  <span class="c1"># We set logging to false since we don&#39;t need it</span>

        <span class="n">test_res</span> <span class="o">=</span> <span class="n">exp</span><span class="o">.</span><span class="n">test</span><span class="p">(</span><span class="n">test_generator</span><span class="p">,</span> <span class="n">seed</span><span class="o">=</span><span class="n">seed</span><span class="p">,</span> <span class="n">callbacks</span><span class="o">=</span><span class="n">callbacks</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">verbose</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">test_res</span></div>

    <span class="k">def</span> <span class="nf">_fill_tagged_addresses_components</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">tags_predictions</span><span class="p">:</span> <span class="n">List</span><span class="p">,</span>
        <span class="n">tags_predictions_prob</span><span class="p">:</span> <span class="n">List</span><span class="p">,</span>
        <span class="n">addresses_to_parse</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">],</span>
        <span class="n">clean_addresses</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">],</span>
        <span class="n">with_prob</span><span class="p">:</span> <span class="nb">bool</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Union</span><span class="p">[</span><span class="n">FormattedParsedAddress</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="n">FormattedParsedAddress</span><span class="p">]]:</span>
        <span class="c1"># pylint: disable=too-many-arguments, too-many-locals</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Method to fill the mapping for every address between a address components and is associated predicted tag (or</span>
<span class="sd">        tag and prob).</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">tagged_addresses_components</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="p">(</span>
            <span class="n">address_to_parse</span><span class="p">,</span>
            <span class="n">clean_address</span><span class="p">,</span>
            <span class="n">tags_prediction</span><span class="p">,</span>
            <span class="n">tags_prediction_prob</span><span class="p">,</span>
        <span class="p">)</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">addresses_to_parse</span><span class="p">,</span> <span class="n">clean_addresses</span><span class="p">,</span> <span class="n">tags_predictions</span><span class="p">,</span> <span class="n">tags_predictions_prob</span><span class="p">):</span>
            <span class="n">tagged_address_components</span> <span class="o">=</span> <span class="p">[]</span>
            <span class="k">for</span> <span class="n">word</span><span class="p">,</span> <span class="n">predicted_idx_tag</span><span class="p">,</span> <span class="n">tag_proba</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">clean_address</span><span class="o">.</span><span class="n">split</span><span class="p">(),</span> <span class="n">tags_prediction</span><span class="p">,</span> <span class="n">tags_prediction_prob</span><span class="p">):</span>
                <span class="n">tag</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">tags_converter</span><span class="p">(</span><span class="n">predicted_idx_tag</span><span class="p">)</span>
                <span class="k">if</span> <span class="n">with_prob</span><span class="p">:</span>
                    <span class="n">tag</span> <span class="o">=</span> <span class="p">(</span><span class="n">tag</span><span class="p">,</span> <span class="nb">round</span><span class="p">(</span><span class="n">tag_proba</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">rounding</span><span class="p">))</span>
                <span class="n">tagged_address_components</span><span class="o">.</span><span class="n">append</span><span class="p">((</span><span class="n">word</span><span class="p">,</span> <span class="n">tag</span><span class="p">))</span>
            <span class="n">tagged_addresses_components</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">FormattedParsedAddress</span><span class="p">({</span><span class="n">address_to_parse</span><span class="p">:</span> <span class="n">tagged_address_components</span><span class="p">}))</span>

        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">tagged_addresses_components</span><span class="p">)</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">tagged_addresses_components</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="k">return</span> <span class="n">tagged_addresses_components</span>

    <span class="k">def</span> <span class="nf">_process_device</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">device</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="nb">str</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">])</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Function to process the device depending on the argument type.</span>

<span class="sd">        Set the device as a torch device object.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">device</span> <span class="o">==</span> <span class="s2">&quot;cpu&quot;</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">device</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s2">&quot;cpu&quot;</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">():</span>
                <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">device</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">):</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">device</span> <span class="o">=</span> <span class="n">device</span>
                <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">device</span><span class="p">,</span> <span class="nb">str</span><span class="p">):</span>
                    <span class="k">if</span> <span class="n">re</span><span class="o">.</span><span class="n">fullmatch</span><span class="p">(</span><span class="sa">r</span><span class="s2">&quot;cuda:\d+&quot;</span><span class="p">,</span> <span class="n">device</span><span class="o">.</span><span class="n">lower</span><span class="p">()):</span>
                        <span class="bp">self</span><span class="o">.</span><span class="n">device</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
                    <span class="k">else</span><span class="p">:</span>
                        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;String value should follow the pattern &#39;cuda:[int]&#39;.&quot;</span><span class="p">)</span>
                <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">device</span><span class="p">,</span> <span class="nb">int</span><span class="p">):</span>
                    <span class="k">if</span> <span class="n">device</span> <span class="o">&gt;=</span> <span class="mi">0</span><span class="p">:</span>
                        <span class="bp">self</span><span class="o">.</span><span class="n">device</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;cuda:</span><span class="si">{</span><span class="n">device</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
                    <span class="k">else</span><span class="p">:</span>
                        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Device should not be a negative number.&quot;</span><span class="p">)</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Device should be a string, an int or a torch device.&quot;</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">warnings</span><span class="o">.</span><span class="n">warn</span><span class="p">(</span><span class="s2">&quot;No CUDA device detected, device will be set to &#39;CPU&#39;.&quot;</span><span class="p">)</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">device</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s2">&quot;cpu&quot;</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">_set_data_transformer</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">DataTransform</span><span class="p">:</span>
        <span class="n">train_vectorizer</span> <span class="o">=</span> <span class="n">TrainVectorizer</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">vectorizer</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">tags_converter</span><span class="p">)</span>  <span class="c1"># Vectorize to provide also the target</span>
        <span class="n">data_transform</span> <span class="o">=</span> <span class="n">DataTransform</span><span class="p">(</span>
            <span class="n">train_vectorizer</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">model_type</span>
        <span class="p">)</span>  <span class="c1"># Use for transforming the data prior to training</span>
        <span class="k">return</span> <span class="n">data_transform</span>

    <span class="k">def</span> <span class="nf">_create_training_data_generator</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">dataset_container</span><span class="p">:</span> <span class="n">DatasetContainer</span><span class="p">,</span>
        <span class="n">train_ratio</span><span class="p">:</span> <span class="nb">float</span><span class="p">,</span>
        <span class="n">batch_size</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
        <span class="n">num_workers</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
        <span class="n">seed</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tuple</span><span class="p">:</span>
        <span class="c1"># pylint: disable=too-many-arguments</span>
        <span class="n">data_transform</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_set_data_transformer</span><span class="p">()</span>

        <span class="n">train_indices</span><span class="p">,</span> <span class="n">valid_indices</span> <span class="o">=</span> <span class="n">indices_splitting</span><span class="p">(</span>
            <span class="n">num_data</span><span class="o">=</span><span class="nb">len</span><span class="p">(</span><span class="n">dataset_container</span><span class="p">),</span> <span class="n">train_ratio</span><span class="o">=</span><span class="n">train_ratio</span><span class="p">,</span> <span class="n">seed</span><span class="o">=</span><span class="n">seed</span>
        <span class="p">)</span>

        <span class="n">train_dataset</span> <span class="o">=</span> <span class="n">Subset</span><span class="p">(</span><span class="n">dataset_container</span><span class="p">,</span> <span class="n">train_indices</span><span class="p">)</span>
        <span class="n">train_generator</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span>
            <span class="n">train_dataset</span><span class="p">,</span>
            <span class="n">collate_fn</span><span class="o">=</span><span class="n">data_transform</span><span class="o">.</span><span class="n">teacher_forcing_transform</span><span class="p">,</span>
            <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span>
            <span class="n">num_workers</span><span class="o">=</span><span class="n">num_workers</span><span class="p">,</span>
            <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
        <span class="p">)</span>

        <span class="n">valid_dataset</span> <span class="o">=</span> <span class="n">Subset</span><span class="p">(</span><span class="n">dataset_container</span><span class="p">,</span> <span class="n">valid_indices</span><span class="p">)</span>
        <span class="n">valid_generator</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span>
            <span class="n">valid_dataset</span><span class="p">,</span>
            <span class="n">collate_fn</span><span class="o">=</span><span class="n">data_transform</span><span class="o">.</span><span class="n">output_transform</span><span class="p">,</span>
            <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span>
            <span class="n">num_workers</span><span class="o">=</span><span class="n">num_workers</span><span class="p">,</span>
        <span class="p">)</span>

        <span class="k">return</span> <span class="n">train_generator</span><span class="p">,</span> <span class="n">valid_generator</span>

    <span class="k">def</span> <span class="nf">_model_factory</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">verbose</span><span class="p">:</span> <span class="nb">bool</span><span class="p">,</span>
        <span class="n">path_to_retrained_model</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="kc">None</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">prediction_layer_len</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">9</span><span class="p">,</span>
        <span class="n">attention_mechanism</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
        <span class="n">seq2seq_kwargs</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="nb">dict</span><span class="p">,</span> <span class="kc">None</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="c1"># pylint: disable=too-many-arguments</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Model factory to create the vectorizer, the data converter and the pre-trained model</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># We switch the case where seq2seq_kwargs is None to an empty dict</span>
        <span class="n">seq2seq_kwargs</span> <span class="o">=</span> <span class="n">seq2seq_kwargs</span> <span class="k">if</span> <span class="n">seq2seq_kwargs</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="p">{}</span>

        <span class="k">if</span> <span class="s2">&quot;fasttext&quot;</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">model_type</span><span class="p">:</span>
            <span class="k">if</span> <span class="s2">&quot;fasttext-light&quot;</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">model_type</span><span class="p">:</span>
                <span class="n">file_name</span> <span class="o">=</span> <span class="n">download_fasttext_magnitude_embeddings</span><span class="p">(</span><span class="n">saving_dir</span><span class="o">=</span><span class="n">CACHE_PATH</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="n">verbose</span><span class="p">)</span>

                <span class="n">embeddings_model</span> <span class="o">=</span> <span class="n">MagnitudeEmbeddingsModel</span><span class="p">(</span><span class="n">file_name</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="n">verbose</span><span class="p">)</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">vectorizer</span> <span class="o">=</span> <span class="n">MagnitudeVectorizer</span><span class="p">(</span><span class="n">embeddings_model</span><span class="o">=</span><span class="n">embeddings_model</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">file_name</span> <span class="o">=</span> <span class="n">download_fasttext_embeddings</span><span class="p">(</span><span class="n">saving_dir</span><span class="o">=</span><span class="n">CACHE_PATH</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="n">verbose</span><span class="p">)</span>

                <span class="n">embeddings_model</span> <span class="o">=</span> <span class="n">FastTextEmbeddingsModel</span><span class="p">(</span><span class="n">file_name</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="n">verbose</span><span class="p">)</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">vectorizer</span> <span class="o">=</span> <span class="n">FastTextVectorizer</span><span class="p">(</span><span class="n">embeddings_model</span><span class="o">=</span><span class="n">embeddings_model</span><span class="p">)</span>

            <span class="bp">self</span><span class="o">.</span><span class="n">data_converter</span> <span class="o">=</span> <span class="n">fasttext_data_padding</span>

            <span class="bp">self</span><span class="o">.</span><span class="n">model</span> <span class="o">=</span> <span class="n">FastTextSeq2SeqModel</span><span class="p">(</span>
                <span class="n">device</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">,</span>
                <span class="n">output_size</span><span class="o">=</span><span class="n">prediction_layer_len</span><span class="p">,</span>
                <span class="n">verbose</span><span class="o">=</span><span class="n">verbose</span><span class="p">,</span>
                <span class="n">path_to_retrained_model</span><span class="o">=</span><span class="n">path_to_retrained_model</span><span class="p">,</span>
                <span class="n">attention_mechanism</span><span class="o">=</span><span class="n">attention_mechanism</span><span class="p">,</span>
                <span class="o">**</span><span class="n">seq2seq_kwargs</span><span class="p">,</span>
            <span class="p">)</span>

        <span class="k">elif</span> <span class="s2">&quot;bpemb&quot;</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">model_type</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">vectorizer</span> <span class="o">=</span> <span class="n">BPEmbVectorizer</span><span class="p">(</span><span class="n">embeddings_model</span><span class="o">=</span><span class="n">BPEmbEmbeddingsModel</span><span class="p">(</span><span class="n">verbose</span><span class="o">=</span><span class="n">verbose</span><span class="p">))</span>

            <span class="bp">self</span><span class="o">.</span><span class="n">data_converter</span> <span class="o">=</span> <span class="n">bpemb_data_padding</span>

            <span class="bp">self</span><span class="o">.</span><span class="n">model</span> <span class="o">=</span> <span class="n">BPEmbSeq2SeqModel</span><span class="p">(</span>
                <span class="n">device</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">,</span>
                <span class="n">output_size</span><span class="o">=</span><span class="n">prediction_layer_len</span><span class="p">,</span>
                <span class="n">verbose</span><span class="o">=</span><span class="n">verbose</span><span class="p">,</span>
                <span class="n">path_to_retrained_model</span><span class="o">=</span><span class="n">path_to_retrained_model</span><span class="p">,</span>
                <span class="n">attention_mechanism</span><span class="o">=</span><span class="n">attention_mechanism</span><span class="p">,</span>
                <span class="o">**</span><span class="n">seq2seq_kwargs</span><span class="p">,</span>
            <span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;There is no </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">model_type</span><span class="si">}</span><span class="s2"> network implemented. Value should be: &quot;</span>
                <span class="sa">f</span><span class="s2">&quot;fasttext, bpemb, lightest (fasttext-light), fastest (fasttext) &quot;</span>
                <span class="sa">f</span><span class="s2">&quot;or best (bpemb).&quot;</span>
            <span class="p">)</span>

    <span class="k">def</span> <span class="nf">_predict_pipeline</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">data</span><span class="p">:</span> <span class="n">List</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tuple</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Pipeline to process data in a data loader for prediction.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">data_converter</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">vectorizer</span><span class="p">(</span><span class="n">data</span><span class="p">))</span>

<div class="viewcode-block" id="AddressParser.get_formatted_model_name"><a class="viewcode-back" href="../../../parser.html#deepparse.parser.AddressParser.get_formatted_model_name">[docs]</a>    <span class="k">def</span> <span class="nf">get_formatted_model_name</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">str</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Return the model type formatted name. For example, if the model type is `&#39;fasttext&#39;` the formatted name is</span>
<span class="sd">        `&quot;FastText&quot;`.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_model_type_formatted</span></div>

    <span class="k">def</span> <span class="nf">_retrain</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">experiment</span><span class="p">:</span> <span class="n">Experiment</span><span class="p">,</span>
        <span class="n">train_generator</span><span class="p">:</span> <span class="n">DatasetContainer</span><span class="p">,</span>
        <span class="n">valid_generator</span><span class="p">:</span> <span class="n">DatasetContainer</span><span class="p">,</span>
        <span class="n">epochs</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
        <span class="n">seed</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
        <span class="n">callbacks</span><span class="p">:</span> <span class="n">List</span><span class="p">,</span>
        <span class="n">disable_tensorboard</span><span class="p">:</span> <span class="nb">bool</span><span class="p">,</span>
        <span class="n">capturing_context</span><span class="p">:</span> <span class="nb">bool</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">List</span><span class="p">[</span><span class="n">Dict</span><span class="p">]:</span>
        <span class="c1"># pylint: disable=too-many-arguments</span>
        <span class="c1"># If Poutyne 1.7 and before, we capture poutyne print since it print some exception.</span>
        <span class="c1"># Otherwise, we use a null context manager.</span>
        <span class="k">with</span> <span class="n">Capturing</span><span class="p">()</span> <span class="k">if</span> <span class="n">capturing_context</span> <span class="k">else</span> <span class="n">contextlib</span><span class="o">.</span><span class="n">nullcontext</span><span class="p">():</span>
            <span class="n">train_res</span> <span class="o">=</span> <span class="n">experiment</span><span class="o">.</span><span class="n">train</span><span class="p">(</span>
                <span class="n">train_generator</span><span class="p">,</span>
                <span class="n">valid_generator</span><span class="o">=</span><span class="n">valid_generator</span><span class="p">,</span>
                <span class="n">epochs</span><span class="o">=</span><span class="n">epochs</span><span class="p">,</span>
                <span class="n">seed</span><span class="o">=</span><span class="n">seed</span><span class="p">,</span>
                <span class="n">callbacks</span><span class="o">=</span><span class="n">callbacks</span><span class="p">,</span>
                <span class="n">verbose</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">verbose</span><span class="p">,</span>
                <span class="n">disable_tensorboard</span><span class="o">=</span><span class="n">disable_tensorboard</span><span class="p">,</span>
            <span class="p">)</span>
        <span class="k">return</span> <span class="n">train_res</span>

    <span class="k">def</span> <span class="nf">_freeze_model_params</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">layers_to_freeze</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="nb">str</span><span class="p">])</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">layers_to_freeze</span> <span class="o">=</span> <span class="n">layers_to_freeze</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span>
        <span class="k">if</span> <span class="n">layers_to_freeze</span> <span class="ow">not</span> <span class="ow">in</span> <span class="p">[</span><span class="s2">&quot;encoder&quot;</span><span class="p">,</span> <span class="s2">&quot;decoder&quot;</span><span class="p">,</span> <span class="s2">&quot;prediction_layer&quot;</span><span class="p">,</span> <span class="s2">&quot;seq2seq&quot;</span><span class="p">]:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">layers_to_freeze</span><span class="si">}</span><span class="s2"> freezing setting is not supported. Value can be &#39;encoder&#39;, &#39;decoder&#39;, &quot;</span>
                <span class="sa">f</span><span class="s2">&quot;&#39;prediction_layer&#39; and &#39;seq2seq&#39;. See doc for more details.&quot;</span>
            <span class="p">)</span>
        <span class="n">layer_exclude</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="k">if</span> <span class="n">layers_to_freeze</span> <span class="o">==</span> <span class="s2">&quot;decoder&quot;</span><span class="p">:</span>
            <span class="n">layers_to_freeze</span> <span class="o">=</span> <span class="p">[</span><span class="n">layers_to_freeze</span> <span class="o">+</span> <span class="s2">&quot;.&quot;</span><span class="p">]</span>
            <span class="k">if</span> <span class="s2">&quot;bpemb&quot;</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">model_type</span><span class="p">:</span>
                <span class="n">layers_to_freeze</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="s2">&quot;embedding_network.&quot;</span><span class="p">)</span>
            <span class="n">layer_exclude</span> <span class="o">=</span> <span class="s2">&quot;decoder.linear.&quot;</span>
        <span class="k">elif</span> <span class="n">layers_to_freeze</span> <span class="o">==</span> <span class="s1">&#39;prediction_layer&#39;</span><span class="p">:</span>
            <span class="n">layers_to_freeze</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;decoder.linear.&quot;</span><span class="p">]</span>
        <span class="k">elif</span> <span class="s1">&#39;seq2seq&#39;</span> <span class="ow">in</span> <span class="n">layers_to_freeze</span><span class="p">:</span>
            <span class="n">layers_to_freeze</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;encoder.&quot;</span><span class="p">,</span> <span class="s2">&quot;decoder.&quot;</span><span class="p">]</span>
            <span class="k">if</span> <span class="s2">&quot;bpemb&quot;</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">model_type</span><span class="p">:</span>
                <span class="n">layers_to_freeze</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="s2">&quot;embedding_network.&quot;</span><span class="p">)</span>
            <span class="n">layer_exclude</span> <span class="o">=</span> <span class="s2">&quot;decoder.linear.&quot;</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">layers_to_freeze</span> <span class="o">=</span> <span class="p">[</span><span class="n">layers_to_freeze</span> <span class="o">+</span> <span class="s2">&quot;.&quot;</span><span class="p">]</span>

        <span class="k">for</span> <span class="n">layer_name</span><span class="p">,</span> <span class="n">param</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">named_parameters</span><span class="p">():</span>
            <span class="c1"># If the layer name is in the layer list to freeze, we set the weights update to false</span>
            <span class="c1"># except if the layer name is a layers exclude. Namely, the decoder.linear when we freeze the decoder,</span>
            <span class="c1"># but we expect the final layer to be unfrozen.</span>
            <span class="c1"># The layers_exclude is not None was added since the base case: &quot;&quot; not in layer_name is equal to False.</span>
            <span class="k">if</span> <span class="nb">any</span><span class="p">(</span><span class="n">layer_to_freeze</span> <span class="k">for</span> <span class="n">layer_to_freeze</span> <span class="ow">in</span> <span class="n">layers_to_freeze</span> <span class="k">if</span> <span class="n">layer_to_freeze</span> <span class="ow">in</span> <span class="n">layer_name</span><span class="p">):</span>
                <span class="k">if</span> <span class="n">layer_exclude</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                    <span class="c1"># Meaning we don&#39;t have a layer to exclude from the layer to freeze.</span>
                    <span class="n">param</span><span class="o">.</span><span class="n">requires_grad</span> <span class="o">=</span> <span class="kc">False</span>
                <span class="k">elif</span> <span class="n">layer_exclude</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">layer_name</span><span class="p">:</span>
                    <span class="c1"># Meaning the layer is not in the layer to exclude from the layer to freeze.</span>
                    <span class="n">param</span><span class="o">.</span><span class="n">requires_grad</span> <span class="o">=</span> <span class="kc">False</span></div>
                <span class="c1"># The implicit else mean the layer_name is in a layers to exclude BUT it is a layer to exclude from</span>
                <span class="c1"># the freezing. Namely, the decoder.linear when we freeze the decoder, but we expect the final layer</span>
                <span class="c1"># to be unfrozen.</span>
</pre></div>

           </div>
          </div>
          <footer>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2020-2022, Marouane Yassine &amp; David Beauchemin.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>